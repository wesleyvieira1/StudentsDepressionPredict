{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "401db4ca",
   "metadata": {},
   "source": [
    "# Análise Comparativa de Modelos de Machine Learning\n",
    "## Classificação de Depressão em Estudantes\n",
    "\n",
    "### Objetivo do Projeto\n",
    "Este projeto implementa e compara três diferentes algoritmos de machine learning para classificação binária de depressão em estudantes:\n",
    "- **Support Vector Machine (SVM)**\n",
    "- **Árvore de Decisão**\n",
    "- **Redes Neurais**\n",
    "\n",
    "### Metodologia\n",
    "- Dataset balanceado (50% / 50%)\n",
    "- Divisão treino/teste: 80% / 20%\n",
    "- Validação cruzada para otimização de hiperparâmetros\n",
    "- Métricas: Accuracy, Precision, Recall, F1-Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f30c402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "751bac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Função para carregar arquivo de métricas\n",
    "def load_metrics(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'rb') as f:\n",
    "            return pickle.load(f)\n",
    "    except Exception as e:\n",
    "        print(f\"Erro ao carregar {file_path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af516442",
   "metadata": {},
   "source": [
    "## 1. Resultados dos Modelos\n",
    "\n",
    "### Consolidação dos Resultados Obtidos\n",
    "Os resultados abaixo foram coletados dos notebooks individuais de cada modelo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90249040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Caminhos para os arquivos de métricas\n",
    "svm_metrics_path = \"modelos/models/metricas_svm.pkl\"\n",
    "arvore_metrics_path = \"modelos/models/arvore_decisao_info.pkl\"\n",
    "nn_metrics_path = \"modelos/models/metricas_modelo_rede_neurais.pkl\"\n",
    "\n",
    "# Carregar métricas dos modelos\n",
    "svm_metrics = load_metrics(svm_metrics_path)\n",
    "arvore_metrics = load_metrics(arvore_metrics_path)\n",
    "nn_metrics = load_metrics(nn_metrics_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5241ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converter métricas para o formato do DataFrame\n",
    "svm_results = {\n",
    "    'Modelo': 'SVM',\n",
    "    'Accuracy': svm_metrics['accuracy'],\n",
    "    'Precision_0': svm_metrics['precision_0'],\n",
    "    'Recall_0': svm_metrics['recall_0'],\n",
    "    'F1_Score_0': svm_metrics['f1_score_0'],\n",
    "    'Precision_1': svm_metrics['precision_1'],\n",
    "    'Recall_1': svm_metrics['recall_1'],\n",
    "    'F1_Score_1': svm_metrics['f1_score_1'],\n",
    "    'Ein': svm_metrics['ein'],\n",
    "    'Eout': svm_metrics['eout']\n",
    "}\n",
    "\n",
    "# Adaptação para o formato de métricas da Árvore de Decisão\n",
    "arvore_results = {\n",
    "    'Modelo': 'Árvore de Decisão',\n",
    "    'Accuracy': arvore_metrics['accuracy'],\n",
    "    'Precision_0': arvore_metrics['precision_0'] if 'precision_0' in arvore_metrics else arvore_metrics['precision'],\n",
    "    'Recall_0': arvore_metrics['recall_0'] if 'recall_0' in arvore_metrics else arvore_metrics['recall'],\n",
    "    'F1_Score_0': arvore_metrics['f1_score_0'] if 'f1_score_0' in arvore_metrics else arvore_metrics['f1_score'],\n",
    "    'Precision_1': arvore_metrics['precision_1'] if 'precision_1' in arvore_metrics else arvore_metrics['precision'],\n",
    "    'Recall_1': arvore_metrics['recall_1'] if 'recall_1' in arvore_metrics else arvore_metrics['recall'],\n",
    "    'F1_Score_1': arvore_metrics['f1_score_1'] if 'f1_score_1' in arvore_metrics else arvore_metrics['f1_score'],\n",
    "    'Ein': arvore_metrics['ein'],\n",
    "    'Eout': arvore_metrics['eout']\n",
    "}\n",
    "\n",
    "redes_results = {\n",
    "    'Modelo': 'Redes Neurais',\n",
    "    'Accuracy': nn_metrics['accuracy'], \n",
    "    'Precision_0': nn_metrics['precision_0'],\n",
    "    'Recall_0': nn_metrics['recall_0'],\n",
    "    'F1_Score_0': nn_metrics['f1_score_0'],\n",
    "    'Precision_1': nn_metrics['precision_1'],\n",
    "    'Recall_1': nn_metrics['recall_1'],\n",
    "    'F1_Score_1': nn_metrics['f1_score_1'],\n",
    "    'Ein': nn_metrics['ein'],\n",
    "    'Eout': nn_metrics['eout']\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "76db52a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== RESULTADOS CONSOLIDADOS ===\n",
      "              Modelo  Accuracy  F1_Score_0  F1_Score_1  Recall_0  Recall_1\n",
      "0                SVM  0.825142    0.822740    0.827479  0.807018  0.843473\n",
      "1  Árvore de Decisão  0.817580    0.817600    0.817600  0.817580  0.817580\n",
      "2      Redes Neurais  0.824827    0.826223    0.826223  0.829868  0.829868\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Criar DataFrame com os resultados\n",
    "results_df = pd.DataFrame([svm_results, arvore_results, redes_results])\n",
    "\n",
    "print(\"=== RESULTADOS CONSOLIDADOS ===\")\n",
    "print(results_df[['Modelo', 'Accuracy', 'F1_Score_0', 'F1_Score_1', 'Recall_0', 'Recall_1']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d7d9573",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== ANÁLISE COMPARATIVA DETALHADA ===\n",
      "\n",
      "1. MÉTRICAS PRINCIPAIS:\n",
      "--------------------------------------------------\n",
      "SVM                  | Accuracy: 0.825 | F1-Score Médio: 0.825\n",
      "Árvore de Decisão    | Accuracy: 0.818 | F1-Score Médio: 0.818\n",
      "Redes Neurais        | Accuracy: 0.825 | F1-Score Médio: 0.826\n",
      "\n",
      "2. ANÁLISE DE OVERFITTING (Ein vs Eout):\n",
      "--------------------------------------------------\n",
      "SVM                  | Ein: 0.1689 | Eout: 0.1749 | Diff: 0.0060 | ✓ Bom\n",
      "Árvore de Decisão    | Ein: 0.1790 | Eout: 0.1824 | Diff: 0.0034 | ✓ Bom\n",
      "Redes Neurais        | Ein: 0.1760 | Eout: 0.1752 | Diff: -0.0008 | ✓ Bom\n",
      "\n",
      "3. BALANCEAMENTO ENTRE CLASSES:\n",
      "--------------------------------------------------\n",
      "SVM                  | F1 Classe 0: 0.823 | F1 Classe 1: 0.827 | Diff: 0.005 | ✓ Balanceado\n",
      "Árvore de Decisão    | F1 Classe 0: 0.818 | F1 Classe 1: 0.818 | Diff: 0.000 | ✓ Balanceado\n",
      "Redes Neurais        | F1 Classe 0: 0.826 | F1 Classe 1: 0.826 | Diff: 0.000 | ✓ Balanceado\n",
      "\n",
      "4. SCORE FINAL PONDERADO:\n",
      "--------------------------------------------------\n",
      "Redes Neurais        | Score Final: 0.6264\n",
      "Árvore de Decisão    | Score Final: 0.6155\n",
      "SVM                  | Score Final: 0.6132\n",
      "\n",
      "============================================================\n",
      "RESULTADO FINAL:\n",
      "============================================================\n",
      "MELHOR MODELO: Redes Neurais\n",
      "Score Final: 0.6264\n",
      "Accuracy: 0.825\n",
      "F1-Score Médio: 0.826\n",
      "Overfitting: -0.0008 (Controlado)\n",
      "\n",
      "JUSTIFICATIVA:\n",
      "------------------------------------------------------------\n",
      "✓ Melhor generalização (menor Eout)\n",
      "✓ Boa performance geral\n",
      "✓ Flexibilidade para dados complexos\n",
      "\n",
      "CONCLUSÃO: O modelo Redes Neurais é o mais adequado para este problema de classificação de depressão.\n"
     ]
    }
   ],
   "source": [
    "# Análise detalhada dos modelos\n",
    "print(\"=== ANÁLISE COMPARATIVA DETALHADA ===\\n\")\n",
    "\n",
    "# 1. Comparação das métricas principais\n",
    "print(\"1. MÉTRICAS PRINCIPAIS:\")\n",
    "print(\"-\" * 50)\n",
    "for index, row in results_df.iterrows():\n",
    "    print(f\"{row['Modelo']:<20} | Accuracy: {row['Accuracy']:.3f} | F1-Score Médio: {(row['F1_Score_0'] + row['F1_Score_1'])/2:.3f}\")\n",
    "\n",
    "# 2. Análise de overfitting (Ein vs Eout)\n",
    "print(\"\\n2. ANÁLISE DE OVERFITTING (Ein vs Eout):\")\n",
    "print(\"-\" * 50)\n",
    "results_df['Overfitting'] = results_df['Eout'] - results_df['Ein']\n",
    "for index, row in results_df.iterrows():\n",
    "    status = \"✓ Bom\" if abs(row['Overfitting']) < 0.02 else \"⚠ Overfitting\" if row['Overfitting'] > 0.02 else \"⚠ Underfitting\"\n",
    "    print(f\"{row['Modelo']:<20} | Ein: {row['Ein']:.4f} | Eout: {row['Eout']:.4f} | Diff: {row['Overfitting']:.4f} | {status}\")\n",
    "\n",
    "# 3. Balanceamento entre classes\n",
    "print(\"\\n3. BALANCEAMENTO ENTRE CLASSES:\")\n",
    "print(\"-\" * 50)\n",
    "for index, row in results_df.iterrows():\n",
    "    f1_diff = abs(row['F1_Score_0'] - row['F1_Score_1'])\n",
    "    balance_status = \"✓ Balanceado\" if f1_diff < 0.02 else \"⚠ Desbalanceado\"\n",
    "    print(f\"{row['Modelo']:<20} | F1 Classe 0: {row['F1_Score_0']:.3f} | F1 Classe 1: {row['F1_Score_1']:.3f} | Diff: {f1_diff:.3f} | {balance_status}\")\n",
    "\n",
    "# 4. Cálculo do score final ponderado\n",
    "print(\"\\n4. SCORE FINAL PONDERADO:\")\n",
    "print(\"-\" * 50)\n",
    "\n",
    "def calculate_final_score(row):\n",
    "    # Peso para accuracy (30%)\n",
    "    accuracy_score = row['Accuracy'] * 0.3\n",
    "    \n",
    "    # Peso para F1-Score médio (40%)\n",
    "    f1_mean = (row['F1_Score_0'] + row['F1_Score_1']) / 2\n",
    "    f1_score = f1_mean * 0.4\n",
    "    \n",
    "    # Penalidade por overfitting (20%)\n",
    "    overfitting_penalty = max(0, 0.2 - abs(row['Overfitting']) * 10) * 0.2\n",
    "    \n",
    "    # Penalidade por desbalanceamento (10%)\n",
    "    balance_penalty = max(0, 0.1 - abs(row['F1_Score_0'] - row['F1_Score_1']) * 5) * 0.1\n",
    "    \n",
    "    return accuracy_score + f1_score + overfitting_penalty + balance_penalty\n",
    "\n",
    "results_df['Score_Final'] = results_df.apply(calculate_final_score, axis=1)\n",
    "\n",
    "# Ordenar por score final\n",
    "results_df_sorted = results_df.sort_values('Score_Final', ascending=False)\n",
    "\n",
    "for index, row in results_df_sorted.iterrows():\n",
    "    print(f\"{row['Modelo']:<20} | Score Final: {row['Score_Final']:.4f}\")\n",
    "\n",
    "# 5. Determinação do melhor modelo\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"RESULTADO FINAL:\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "best_model = results_df_sorted.iloc[0]\n",
    "print(f\"MELHOR MODELO: {best_model['Modelo']}\")\n",
    "print(f\"Score Final: {best_model['Score_Final']:.4f}\")\n",
    "print(f\"Accuracy: {best_model['Accuracy']:.3f}\")\n",
    "print(f\"F1-Score Médio: {(best_model['F1_Score_0'] + best_model['F1_Score_1'])/2:.3f}\")\n",
    "print(f\"Overfitting: {best_model['Overfitting']:.4f} {'(Controlado)' if abs(best_model['Overfitting']) < 0.02 else '(Presente)'}\")\n",
    "\n",
    "# 6. Justificativa da escolha\n",
    "print(\"\\nJUSTIFICATIVA:\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "if best_model['Modelo'] == 'SVM':\n",
    "    print(\"✓ Excelente accuracy e F1-score\")\n",
    "    print(\"✓ Boa generalização (Ein vs Eout)\")\n",
    "    print(\"✓ Balanceamento adequado entre classes\")\n",
    "elif best_model['Modelo'] == 'Redes Neurais':\n",
    "    print(\"✓ Melhor generalização (menor Eout)\")\n",
    "    print(\"✓ Boa performance geral\")\n",
    "    print(\"✓ Flexibilidade para dados complexos\")\n",
    "else:\n",
    "    print(\"✓ Interpretabilidade do modelo\")\n",
    "    print(\"✓ Simplicidade e eficiência\")\n",
    "    print(\"✓ Boa performance geral\")\n",
    "\n",
    "print(f\"\\nCONCLUSÃO: O modelo {best_model['Modelo']} é o mais adequado para este problema de classificação de depressão.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
